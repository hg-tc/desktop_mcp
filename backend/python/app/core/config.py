"""
åº”ç”¨é…ç½® - é€‚é…æ¡Œé¢åº”ç”¨
"""
import os
import json
from typing import Dict, List, Optional, Union
from pathlib import Path
from pydantic_settings import BaseSettings
from dotenv import load_dotenv

# ç¡®å®š .env æ–‡ä»¶è·¯å¾„
# ä¼˜å…ˆæŸ¥æ‰¾å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ .envï¼Œç„¶åæŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•
_config_dir = Path(__file__).parent.parent.parent  # app/core -> app -> python
_env_paths = [
    _config_dir / ".env",  # backend/python/.env
    _config_dir.parent / ".env",  # é¡¹ç›®æ ¹ç›®å½•/.env
]

# åŠ è½½ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„ .env æ–‡ä»¶
_env_loaded = False
_env_file_used = None
for env_path in _env_paths:
    if env_path.exists():
        load_dotenv(env_path, override=False)  # override=False è®©ç¯å¢ƒå˜é‡ä¼˜å…ˆ
        _env_loaded = True
        _env_file_used = str(env_path)
        break

# å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œå°è¯•é»˜è®¤è¡Œä¸ºï¼ˆå½“å‰å·¥ä½œç›®å½•ï¼‰
if not _env_loaded:
    load_dotenv(override=False)
    _env_file_used = "current working directory"

# è°ƒè¯•æ—¥å¿—ï¼ˆå§‹ç»ˆè®°å½•ï¼Œå¸®åŠ©è¯Šæ–­é—®é¢˜ï¼‰
import logging
logger = logging.getLogger(__name__)
logger.info(f"ğŸ“ åŠ è½½ .env æ–‡ä»¶: {_env_file_used}")
api_key_from_env = os.getenv('OPENAI_API_KEY')
if api_key_from_env:
    logger.info(f"âœ… OPENAI_API_KEY å·²ä»ç¯å¢ƒå˜é‡è¯»å– (é•¿åº¦: {len(api_key_from_env)})")
else:
    logger.warning("âš ï¸ OPENAI_API_KEY æœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ°")


def get_user_data_path() -> str:
    """è·å–åº”ç”¨æ•°æ®ç›®å½•è·¯å¾„"""
    # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆElectron ä¼šè®¾ç½®ï¼‰
    user_data = os.getenv("USER_DATA_PATH")
    if user_data:
        return user_data
    
    # å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨é¡¹ç›®ç›®å½•
    project_root = Path(__file__).parent.parent.parent.parent
    return str(project_root / "data")


class Settings(BaseSettings):
    """åº”ç”¨è®¾ç½®"""
    
    # é¡¹ç›®ä¿¡æ¯
    PROJECT_NAME: str = "Xiaohongshu Agent Desktop API"
    PROJECT_DESCRIPTION: str = "å°çº¢ä¹¦ Agent æ¡Œé¢åº”ç”¨åç«¯API"
    VERSION: str = "1.0.0"
    API_V1_STR: str = "/api/v1"
    
    # æœåŠ¡å™¨é…ç½®
    HOST: str = "127.0.0.1"
    PORT: int = 18061
    DEBUG: bool = os.getenv("NODE_ENV") != "production"
    
    # æ•°æ®åº“é…ç½®
    # é»˜è®¤ä½¿ç”¨ SQLiteï¼Œå¦‚æœè®¾ç½®äº† DATABASE_URL åˆ™ä½¿ç”¨æŒ‡å®šçš„æ•°æ®åº“
    _user_data = get_user_data_path()
    _default_db_path = os.path.join(_user_data, "app.db")
    DATABASE_URL: str = os.getenv(
        "DATABASE_URL",
        f"sqlite+aiosqlite:///{_default_db_path}"
    )
    
    # æ–‡ä»¶ä¸Šä¼ é…ç½®
    MAX_UPLOAD_SIZE: int = 500 * 1024 * 1024  # 500MB
    UPLOAD_DIR: str = os.path.join(_user_data, "uploads")
    ALLOWED_EXTENSIONS: List[str] = [
        ".pdf", ".docx", ".doc", ".xlsx", ".xls", ".pptx", ".ppt",
        ".txt", ".md", ".json", ".csv", ".jpg", ".jpeg", ".png", ".gif"
    ]
    
    # å¤§æ¨¡å‹APIé…ç½®
    OPENAI_API_KEY: Optional[str] = os.getenv("OPENAI_API_KEY")
    OPENAI_BASE_URL: str = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
    OPENAI_MODEL: str = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    LLM_AUTHORIZATION_TOKEN: Optional[str] = os.getenv("LLM_AUTHORIZATION_TOKEN")
    LLM_API_KEY_HEADER: str = os.getenv("LLM_API_KEY_HEADER", "Authorization")
    LLM_API_KEY_FORMAT: str = os.getenv("LLM_API_KEY_FORMAT", "bearer")
    LLM_CUSTOM_HEADERS: Optional[str] = os.getenv("LLM_CUSTOM_HEADERS")
    
    # è¶…æ—¶é…ç½®
    API_TIMEOUT: int = int(os.getenv("API_TIMEOUT", "300"))
    LLM_REQUEST_TIMEOUT: int = int(os.getenv("LLM_REQUEST_TIMEOUT", "120"))
    
    # LangGraph Agent é…ç½®
    LANGGRAPH_MAX_ITERATIONS: int = int(os.getenv("LANGGRAPH_MAX_ITERATIONS", "10"))  # Agent æœ€å¤§è¿­ä»£æ¬¡æ•°
    
    # Go MCP åç«¯é…ç½®
    MCP_SERVER_URL: Optional[str] = os.getenv("MCP_SERVER_URL")  # Go åç«¯åœ°å€
    
    # CORSé…ç½®ï¼ˆå…è®¸ Electron å‰ç«¯è®¿é—®ï¼‰
    BACKEND_CORS_ORIGINS: List[str] = [
        "http://localhost:5173",  # Vite å¼€å‘æœåŠ¡å™¨
        "http://127.0.0.1:5173",
        "file://",  # Electron æœ¬åœ°æ–‡ä»¶åè®®
    ]
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL: str = os.getenv("LOG_LEVEL", "INFO")
    
    @property
    def user_data_path(self) -> str:
        """è·å–åº”ç”¨æ•°æ®ç›®å½•"""
        return get_user_data_path()
    
    @property
    def database_path(self) -> str:
        """è·å–æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆä»… SQLiteï¼‰"""
        if "sqlite" in self.DATABASE_URL:
            # ä» URL ä¸­æå–è·¯å¾„
            url = self.DATABASE_URL.replace("sqlite+aiosqlite:///", "")
            return url
        return ""
    
    def ensure_directories(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        os.makedirs(self.UPLOAD_DIR, exist_ok=True)
        os.makedirs(os.path.join(self.UPLOAD_DIR, "workspaces"), exist_ok=True)
        os.makedirs(os.path.join(self.UPLOAD_DIR, "global"), exist_ok=True)
        os.makedirs(os.path.dirname(self.database_path) if self.database_path else self.user_data_path, exist_ok=True)
    
    def get_llm_custom_headers(self) -> Dict[str, str]:
        """è§£æ LLM è‡ªå®šä¹‰ headers"""
        if not self.LLM_CUSTOM_HEADERS:
            return {}
        try:
            parsed = json.loads(self.LLM_CUSTOM_HEADERS)
            if not isinstance(parsed, dict):
                logger.warning("LLM_CUSTOM_HEADERS å¿…é¡»æ˜¯ JSON å¯¹è±¡")
                return {}
            headers: Dict[str, str] = {}
            for key, value in parsed.items():
                headers[str(key)] = str(value)
            return headers
        except json.JSONDecodeError as e:
            logger.warning(f"è§£æ LLM_CUSTOM_HEADERS å¤±è´¥: {e}")
            return {}
    
    class Config:
        case_sensitive = True
        env_file = ".env"
        extra = "ignore"


settings = Settings()

# ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
settings.ensure_directories()

# ç¡®ä¿ OpenAI ç›¸å…³ç¯å¢ƒå˜é‡
if settings.OPENAI_API_KEY:
    os.environ.setdefault("OPENAI_API_KEY", settings.OPENAI_API_KEY)
if settings.OPENAI_BASE_URL:
    os.environ.setdefault("OPENAI_BASE_URL", settings.OPENAI_BASE_URL)

